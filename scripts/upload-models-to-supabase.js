/**
 * 3D Modelleri Supabase Storage'a YÃ¼kle
 */

const { createClient } = require('@supabase/supabase-js')
const fs = require('fs')
const path = require('path')

// Supabase config
const supabaseUrl = process.env.NEXT_PUBLIC_SUPABASE_URL
const supabaseServiceKey = process.env.SUPABASE_SERVICE_ROLE_KEY

if (!supabaseUrl || !supabaseServiceKey) {
  console.error('âŒ NEXT_PUBLIC_SUPABASE_URL ve SUPABASE_SERVICE_ROLE_KEY gerekli!')
  console.log('Ã–rnek: node scripts/upload-models-to-supabase.js')
  process.exit(1)
}

const supabase = createClient(supabaseUrl, supabaseServiceKey)

const MODELS_DIR = path.join(__dirname, '../public/models')
const BUCKET_NAME = 'models'

async function uploadModels() {
  console.log('ðŸš€ 3D Model yÃ¼kleme baÅŸlÄ±yor...\n')
  
  // 1. Bucket oluÅŸtur (yoksa)
  const { data: buckets } = await supabase.storage.listBuckets()
  const bucketExists = buckets?.some(b => b.name === BUCKET_NAME)
  
  if (!bucketExists) {
    console.log(`ðŸ“¦ "${BUCKET_NAME}" bucket oluÅŸturuluyor...`)
    const { error } = await supabase.storage.createBucket(BUCKET_NAME, {
      public: true,
      fileSizeLimit: 52428800 // 50MB
    })
    if (error) {
      console.error('âŒ Bucket oluÅŸturulamadÄ±:', error.message)
      return
    }
    console.log('âœ… Bucket oluÅŸturuldu!\n')
  } else {
    console.log(`âœ… "${BUCKET_NAME}" bucket mevcut\n`)
  }
  
  // 2. TÃ¼m .glb dosyalarÄ±nÄ± bul
  const categories = ['anatomy', 'biology', 'chemistry', 'math', 'physics']
  let totalFiles = 0
  let uploadedFiles = 0
  let failedFiles = []
  
  for (const category of categories) {
    const categoryPath = path.join(MODELS_DIR, category)
    
    if (!fs.existsSync(categoryPath)) {
      console.log(`âš ï¸ ${category} klasÃ¶rÃ¼ yok, atlanÄ±yor...`)
      continue
    }
    
    const files = fs.readdirSync(categoryPath).filter(f => f.endsWith('.glb'))
    console.log(`ðŸ“ ${category}: ${files.length} model`)
    
    for (const file of files) {
      totalFiles++
      const filePath = path.join(categoryPath, file)
      const storagePath = `${category}/${file}`
      
      try {
        const fileBuffer = fs.readFileSync(filePath)
        const fileSize = (fileBuffer.length / 1024 / 1024).toFixed(2)
        
        process.stdout.write(`   â¬†ï¸ ${file} (${fileSize}MB)... `)
        
        const { error } = await supabase.storage
          .from(BUCKET_NAME)
          .upload(storagePath, fileBuffer, {
            contentType: 'model/gltf-binary',
            upsert: true
          })
        
        if (error) {
          console.log('âŒ')
          failedFiles.push({ file: storagePath, error: error.message })
        } else {
          console.log('âœ…')
          uploadedFiles++
        }
      } catch (err) {
        console.log('âŒ')
        failedFiles.push({ file: storagePath, error: err.message })
      }
    }
    console.log('')
  }
  
  // 3. SonuÃ§
  console.log('â•'.repeat(50))
  console.log(`ðŸ“Š SonuÃ§: ${uploadedFiles}/${totalFiles} dosya yÃ¼klendi`)
  
  if (failedFiles.length > 0) {
    console.log('\nâŒ BaÅŸarÄ±sÄ±z dosyalar:')
    failedFiles.forEach(f => console.log(`   - ${f.file}: ${f.error}`))
  }
  
  // 4. URL Ã¶rneÄŸi
  const baseUrl = `${supabaseUrl}/storage/v1/object/public/${BUCKET_NAME}`
  console.log(`\nðŸ”— Model URL formatÄ±:`)
  console.log(`   ${baseUrl}/physics/robot.glb`)
}

uploadModels().catch(console.error)
