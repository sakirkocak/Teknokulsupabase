'use client'

/**
 * useGeminiLive Hook
 * Gemini 2.5 Flash Live API ile gerÃ§ek zamanlÄ± sesli sohbet
 * Server-side proxy Ã¼zerinden baÄŸlanÄ±r (CORS sorunu yok)
 * 
 * Ã–zellikler:
 * - Server-side streaming (SSE)
 * - Native audio output
 * - Mikrofon input
 * - VAD (Voice Activity Detection)
 */

import { useState, useRef, useCallback, useEffect } from 'react'

// Types
export type GeminiLiveStatus = 
  | 'idle'
  | 'connecting'
  | 'connected'
  | 'listening'
  | 'speaking'
  | 'processing'
  | 'error'

interface UseGeminiLiveOptions {
  studentName: string
  grade: number
  personality?: 'friendly' | 'strict' | 'motivating'
  voice?: string
  onTranscript?: (text: string, isUser: boolean) => void
  onAudioReceived?: (audioData: string, mimeType: string) => void
  onStatusChange?: (status: GeminiLiveStatus) => void
  onError?: (error: Error) => void
}

interface UseGeminiLiveReturn {
  status: GeminiLiveStatus
  isConnected: boolean
  isListening: boolean
  isSpeaking: boolean
  volume: number
  connect: () => Promise<void>
  disconnect: () => void
  sendText: (text: string) => Promise<void>
  sendAudio: (audioData: string) => Promise<void>
  interrupt: () => void
  error: Error | null
}

export function useGeminiLive(options: UseGeminiLiveOptions): UseGeminiLiveReturn {
  const {
    studentName,
    grade,
    personality = 'friendly',
    voice = 'Kore',
    onTranscript,
    onAudioReceived,
    onStatusChange,
    onError
  } = options
  
  // State
  const [status, setStatus] = useState<GeminiLiveStatus>('idle')
  const [volume, setVolume] = useState(0)
  const [error, setError] = useState<Error | null>(null)
  
  // Refs
  const abortControllerRef = useRef<AbortController | null>(null)
  const audioContextRef = useRef<AudioContext | null>(null)
  const audioQueueRef = useRef<string[]>([])
  const isPlayingRef = useRef(false)
  const mediaStreamRef = useRef<MediaStream | null>(null)
  const reconnectAttempts = useRef(0)
  const maxReconnectAttempts = 3
  const isSessionActive = useRef(false)
  
  // Status deÄŸiÅŸikliÄŸini bildir
  const updateStatus = useCallback((newStatus: GeminiLiveStatus) => {
    setStatus(newStatus)
    onStatusChange?.(newStatus)
  }, [onStatusChange])
  
  // Audio context oluÅŸtur
  const initAudioContext = useCallback(async () => {
    if (!audioContextRef.current) {
      audioContextRef.current = new AudioContext({ sampleRate: 24000 })
    }
    
    if (audioContextRef.current.state === 'suspended') {
      await audioContextRef.current.resume()
    }
    
    return audioContextRef.current
  }, [])
  
  // Gemini audio'yu AudioContext ile Ã§al
  const playGeminiAudio = useCallback(async (base64Audio: string, mimeType: string) => {
    console.log('ğŸ”Š [AUDIO] Ã‡alÄ±nÄ±yor...', mimeType)
    
    try {
      const ctx = await initAudioContext()
      
      // Base64 -> ArrayBuffer
      const binaryString = atob(base64Audio)
      const bytes = new Uint8Array(binaryString.length)
      for (let i = 0; i < binaryString.length; i++) {
        bytes[i] = binaryString.charCodeAt(i)
      }
      
      // Mime type'dan sample rate al (varsayÄ±lan 24000)
      const sampleRate = mimeType.includes('16000') ? 16000 : 24000
      
      // PCM 16-bit -> Float32
      const pcmData = new Int16Array(bytes.buffer)
      const floatData = new Float32Array(pcmData.length)
      for (let i = 0; i < pcmData.length; i++) {
        floatData[i] = pcmData[i] / 32768
      }
      
      // AudioBuffer oluÅŸtur
      const audioBuffer = ctx.createBuffer(1, floatData.length, sampleRate)
      audioBuffer.getChannelData(0).set(floatData)
      
      // Ã‡al
      const source = ctx.createBufferSource()
      source.buffer = audioBuffer
      source.connect(ctx.destination)
      
      isPlayingRef.current = true
      updateStatus('speaking')
      
      // Volume simÃ¼lasyonu (lip-sync)
      const volumeInterval = setInterval(() => {
        if (isPlayingRef.current) {
          setVolume(0.3 + Math.random() * 0.5)
        } else {
          clearInterval(volumeInterval)
          setVolume(0)
        }
      }, 100)
      
      source.onended = () => {
        isPlayingRef.current = false
        setVolume(0)
        clearInterval(volumeInterval)
        console.log('ğŸ”‡ [AUDIO] Bitti')
        
        if (isSessionActive.current) {
          updateStatus('listening')
        }
      }
      
      source.start()
      console.log(`âœ… [AUDIO] Ã‡alÄ±yor: ${floatData.length} samples @ ${sampleRate}Hz`)
      
    } catch (err) {
      console.error('âŒ [AUDIO] Hata:', err)
      // Audio Ã§alamazsa listening'e geÃ§
      if (isSessionActive.current) {
        updateStatus('listening')
      }
    }
  }, [initAudioContext, updateStatus])
  
  // Fallback: Browser TTS
  const speakWithBrowserTTS = useCallback((text: string) => {
    if (!text.trim() || typeof window === 'undefined') return
    
    console.log('ğŸ—£ï¸ [TTS] Browser TTS kullanÄ±lÄ±yor...')
    window.speechSynthesis?.cancel()
    
    const utterance = new SpeechSynthesisUtterance(text)
    utterance.lang = 'tr-TR'
    utterance.rate = 1.0
    
    const voices = window.speechSynthesis?.getVoices() || []
    const turkishVoice = voices.find(v => v.lang.startsWith('tr'))
    if (turkishVoice) utterance.voice = turkishVoice
    
    utterance.onstart = () => {
      isPlayingRef.current = true
      updateStatus('speaking')
    }
    
    utterance.onend = () => {
      isPlayingRef.current = false
      setVolume(0)
      if (isSessionActive.current) updateStatus('listening')
    }
    
    // Volume simÃ¼lasyonu
    const interval = setInterval(() => {
      if (isPlayingRef.current) {
        setVolume(0.3 + Math.random() * 0.5)
      } else {
        clearInterval(interval)
      }
    }, 100)
    
    window.speechSynthesis?.speak(utterance)
  }, [updateStatus])
  
  
  // Mikrofonu baÅŸlat (STT iÃ§in)
  const startMicrophone = useCallback(async () => {
    // Zaten aktifse tekrar baÅŸlatma
    if (mediaStreamRef.current) {
      const tracks = mediaStreamRef.current.getTracks()
      const activeTracks = tracks.filter(t => t.readyState === 'live')
      if (activeTracks.length > 0) {
        console.log('ğŸ¤ [MIC] Mikrofon zaten aktif')
        return true
      }
    }
    
    try {
      console.log('ğŸ¤ [MIC] Mikrofon baÅŸlatÄ±lÄ±yor...')
      
      const stream = await navigator.mediaDevices.getUserMedia({
        audio: {
          sampleRate: 16000,
          channelCount: 1,
          echoCancellation: true,
          noiseSuppression: true,
          autoGainControl: true
        }
      })
      
      // Track ended event'i dinle
      stream.getTracks().forEach(track => {
        track.onended = () => {
          console.warn('âš ï¸ [MIC] Track sonlandÄ±:', track.label)
          
          // Oturum aktifse yeniden baÅŸlat
          if (isSessionActive.current) {
            console.log('ğŸ”„ [MIC] Otomatik yeniden baÅŸlatma...')
            setTimeout(() => {
              if (isSessionActive.current) {
                startMicrophone()
              }
            }, 1000)
          }
        }
        
        track.onmute = () => {
          console.warn('ğŸ”‡ [MIC] Track susturuldu')
        }
        
        track.onunmute = () => {
          console.log('ğŸ”Š [MIC] Track tekrar aktif')
        }
      })
      
      mediaStreamRef.current = stream
      console.log('âœ… [MIC] Mikrofon baÅŸlatÄ±ldÄ±')
      return true
      
    } catch (err: any) {
      console.error('âŒ [MIC] Mikrofon hatasÄ±:', err.name, err.message)
      
      // Hata tÃ¼rÃ¼ne gÃ¶re mesaj
      let errorMessage = 'Mikrofon eriÅŸimi reddedildi'
      if (err.name === 'NotAllowedError') {
        errorMessage = 'Mikrofon izni verilmedi. LÃ¼tfen tarayÄ±cÄ± ayarlarÄ±ndan izin verin.'
      } else if (err.name === 'NotFoundError') {
        errorMessage = 'Mikrofon bulunamadÄ±. LÃ¼tfen bir mikrofon baÄŸlayÄ±n.'
      } else if (err.name === 'NotReadableError') {
        errorMessage = 'Mikrofon kullanÄ±lamÄ±yor. BaÅŸka bir uygulama kullanÄ±yor olabilir.'
      }
      
      const error = new Error(errorMessage)
      setError(error)
      onError?.(error)
      return false
    }
  }, [onError])
  
  // Mikrofonu durdur
  const stopMicrophone = useCallback(() => {
    if (mediaStreamRef.current) {
      mediaStreamRef.current.getTracks().forEach(track => {
        track.onended = null
        track.onmute = null
        track.onunmute = null
        track.stop()
      })
      mediaStreamRef.current = null
      console.log('ğŸ”‡ [MIC] Mikrofon durduruldu')
    }
  }, [])
  
  // Mesaj gÃ¶nder ve yanÄ±t al (streaming)
  const sendMessage = useCallback(async (message: string, isSetup: boolean = false) => {
    // Ã–nceki request'i iptal etme - sadece yeni request baÅŸlat
    const controller = new AbortController()
    abortControllerRef.current = controller
    
    console.log(`ğŸ”µ [HOOK] ${isSetup ? 'Setup' : 'Message'} gÃ¶nderiliyor:`, message.substring(0, 30))
    
    if (isSetup) {
      updateStatus('connecting')
    } else {
      updateStatus('processing')
    }
    
    try {
      const response = await fetch('/api/tekno-teacher/live/stream', {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({
          action: isSetup ? 'setup' : 'text',
          studentName,
          grade,
          personality,
          voice,
          textMessage: isSetup ? null : message
        }),
        signal: controller.signal
      })
      
      console.log('ğŸ“¡ [HOOK] API yanÄ±tÄ±:', response.status)
      
      if (!response.ok) {
        const errorData = await response.json().catch(() => ({ error: 'Bilinmeyen hata' }))
        throw new Error(errorData.error || `HTTP ${response.status}`)
      }
      
      const reader = response.body?.getReader()
      if (!reader) throw new Error('Stream okunamadÄ±')
      
      const decoder = new TextDecoder()
      let buffer = ''
      let fullText = ''
      let gotResponse = false
      let hasAudio = false
      
      updateStatus('processing')
      
      while (true) {
        const { done, value } = await reader.read()
        if (done) {
          console.log('ğŸ“­ [HOOK] Stream bitti, text:', fullText.length, 'karakter')
          break
        }
        
        buffer += decoder.decode(value, { stream: true })
        const lines = buffer.split('\n')
        buffer = lines.pop() || ''
        
        for (const line of lines) {
          if (line.startsWith('data: ')) {
            try {
              const data = JSON.parse(line.slice(6))
              
              // Ping - ignore, sadece log
              if (data.type === 'ping') {
                // console.log('ğŸ’“ ping')
                continue
              }
              
              // BaÄŸlantÄ± onayÄ±
              if (data.type === 'connected') {
                console.log('ğŸŸ¢ [HOOK] BaÄŸlantÄ± onaylandÄ±:', data.studentName)
                reconnectAttempts.current = 0
                continue
              }
              
              // Metin yanÄ±tÄ±
              if (data.type === 'text') {
                gotResponse = true
                fullText += data.content
                console.log('ğŸ“ [HOOK] AI yanÄ±tÄ±:', data.content.substring(0, 50))
                onTranscript?.(data.content, false)
              }
              
              // Audio yanÄ±tÄ± - Gemini'den gelen ses
              if (data.type === 'audio' && data.data) {
                console.log('ğŸ”Š [HOOK] Audio alÄ±ndÄ±:', data.mimeType)
                hasAudio = true
                await playGeminiAudio(data.data, data.mimeType)
              }
              
              // TamamlandÄ± - audio yoksa browser TTS
              if (data.type === 'done') {
                console.log('âœ… [HOOK] Stream bitti, hasAudio:', data.hasAudio)
                if (!data.hasAudio && fullText && !hasAudio) {
                  console.log('ğŸ—£ï¸ [HOOK] Audio yok, browser TTS kullanÄ±lÄ±yor')
                  speakWithBrowserTTS(fullText)
                }
              }
              
              // Hata - ama VAD/no-speech hatasÄ±nÄ± ignore et
              if (data.type === 'error') {
                const errorMsg = data.rawError || data.message || ''
                
                // VAD/no-speech hatalarÄ±nÄ± ignore et
                if (errorMsg.toLowerCase().includes('no speech') || 
                    errorMsg.toLowerCase().includes('no audio') ||
                    errorMsg.toLowerCase().includes('vad')) {
                  console.warn('âš ï¸ [HOOK] VAD hatasÄ± (ignore):', errorMsg)
                  continue // Hata olarak sayma, devam et
                }
                
                console.error('âŒ [HOOK] API hatasÄ±:', data)
                throw new Error(`[${data.code || 'ERR'}] ${errorMsg}`)
              }
              
              // Stream tamamlandÄ±
              if (data.type === 'done' || data.type === 'stream_end') {
                console.log('âœ… [HOOK] Stream tamamlandÄ±, chunks:', data.totalChunks || 0)
              }
              
            } catch (e: any) {
              if (e.message?.startsWith('[')) throw e
              // JSON parse hatasÄ± - devam et
            }
          }
        }
      }
      
      // YanÄ±t alÄ±ndÄ±ysa listening'e geÃ§
      if (gotResponse && isSessionActive.current) {
        console.log('ğŸ§ [HOOK] Listening moduna geÃ§iliyor...')
        updateStatus('listening')
      }
      
      return fullText
      
    } catch (err: any) {
      if (err.name === 'AbortError') {
        console.log('ğŸ›‘ [HOOK] Request iptal edildi')
        return ''
      }
      console.error('âŒ [HOOK] Request hatasÄ±:', err.message)
      throw err
    }
  }, [studentName, grade, personality, voice, updateStatus, playGeminiAudio, speakWithBrowserTTS, onTranscript])
  
  // BaÄŸlantÄ±yÄ± baÅŸlat
  const connect = useCallback(async () => {
    console.log('ğŸš€ [HOOK] BaÄŸlantÄ± baÅŸlatÄ±lÄ±yor...')
    
    updateStatus('connecting')
    setError(null)
    isSessionActive.current = true
    reconnectAttempts.current = 0
    
    try {
      // Ã–nce mikrofonu baÅŸlat
      const micStarted = await startMicrophone()
      if (!micStarted) {
        console.warn('âš ï¸ [HOOK] Mikrofon baÅŸlatÄ±lamadÄ±, metin modu aktif')
      }
      
      // Setup mesajÄ± gÃ¶nder - AI kendini tanÄ±tacak
      console.log('ğŸ“¤ [HOOK] Setup gÃ¶nderiliyor...')
      const response = await sendMessage('', true) // isSetup = true
      
      if (response) {
        console.log('âœ… [HOOK] AI yanÄ±t verdi:', response.substring(0, 50))
      }
      
      // BaÄŸlantÄ± baÅŸarÄ±lÄ± - listening modunda kal
      if (isSessionActive.current) {
        console.log('ğŸ§ [HOOK] Oturum aktif, listening modunda')
        updateStatus('listening')
      }
      
    } catch (err: any) {
      console.error('âŒ [HOOK] BaÄŸlantÄ± hatasÄ±:', err.message)
      
      // Auto-reconnect (3 deneme)
      if (isSessionActive.current && reconnectAttempts.current < maxReconnectAttempts) {
        reconnectAttempts.current++
        console.log(`ğŸ”„ [HOOK] Yeniden baÄŸlanma ${reconnectAttempts.current}/${maxReconnectAttempts}...`)
        
        await new Promise(r => setTimeout(r, 2000))
        
        if (isSessionActive.current) {
          return connect()
        }
      }
      
      isSessionActive.current = false
      setError(err)
      onError?.(err)
      updateStatus('error')
    }
  }, [sendMessage, startMicrophone, updateStatus, onError])
  
  // BaÄŸlantÄ±yÄ± kes
  const disconnect = useCallback(() => {
    console.log('ğŸ”Œ [HOOK] BaÄŸlantÄ± kapatÄ±lÄ±yor...')
    
    isSessionActive.current = false
    reconnectAttempts.current = 0
    
    abortControllerRef.current?.abort()
    abortControllerRef.current = null
    
    stopMicrophone()
    
    if (audioContextRef.current) {
      audioContextRef.current.close().catch(() => {})
      audioContextRef.current = null
    }
    
    audioQueueRef.current = []
    isPlayingRef.current = false
    
    updateStatus('idle')
    setVolume(0)
    setError(null)
    
    console.log('âœ… [HOOK] BaÄŸlantÄ± kapatÄ±ldÄ±')
  }, [stopMicrophone, updateStatus])
  
  // Metin gÃ¶nder
  const sendText = useCallback(async (text: string) => {
    if (!text.trim()) return
    console.log('ğŸ’¬ [HOOK] KullanÄ±cÄ± mesajÄ±:', text.substring(0, 50))
    onTranscript?.(text, true)
    await sendMessage(text, false)
  }, [sendMessage, onTranscript])
  
  // Audio gÃ¶nder (base64) - ÅŸimdilik devre dÄ±ÅŸÄ±
  const sendAudio = useCallback(async (audioData: string) => {
    console.log('ğŸ¤ [HOOK] Audio gÃ¶nderme henÃ¼z desteklenmiyor')
    // TODO: Audio streaming implementasyonu
  }, [])
  
  // KonuÅŸmayÄ± kes
  const interrupt = useCallback(() => {
    abortControllerRef.current?.abort()
    isPlayingRef.current = false
    audioQueueRef.current = []
    setVolume(0)
    updateStatus('listening')
  }, [updateStatus])
  
  // Cleanup
  useEffect(() => {
    return () => {
      disconnect()
    }
  }, [disconnect])
  
  return {
    status,
    isConnected: ['connected', 'listening', 'speaking', 'processing'].includes(status),
    isListening: status === 'listening',
    isSpeaking: status === 'speaking',
    volume,
    connect,
    disconnect,
    sendText,
    sendAudio,
    interrupt,
    error
  }
}

export default useGeminiLive
