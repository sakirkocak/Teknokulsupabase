'use client'

/**
 * useGeminiLive Hook
 * Gemini 2.5 Flash Live API ile ger√ßek zamanlƒ± sesli sohbet
 * Server-side proxy √ºzerinden baƒülanƒ±r (CORS sorunu yok)
 * 
 * √ñzellikler:
 * - Server-side streaming (SSE)
 * - Native audio output
 * - Mikrofon input
 * - VAD (Voice Activity Detection)
 */

import { useState, useRef, useCallback, useEffect } from 'react'

// Types
export type GeminiLiveStatus = 
  | 'idle'
  | 'connecting'
  | 'connected'
  | 'listening'
  | 'speaking'
  | 'processing'
  | 'error'

interface UseGeminiLiveOptions {
  studentName: string
  grade: number
  personality?: 'friendly' | 'strict' | 'motivating'
  voice?: string
  onTranscript?: (text: string, isUser: boolean) => void
  onAudioReceived?: (audioData: string, mimeType: string) => void
  onStatusChange?: (status: GeminiLiveStatus) => void
  onError?: (error: Error) => void
}

interface UseGeminiLiveReturn {
  status: GeminiLiveStatus
  isConnected: boolean
  isListening: boolean
  isSpeaking: boolean
  volume: number
  connect: () => Promise<void>
  disconnect: () => void
  sendText: (text: string) => Promise<void>
  sendAudio: (audioData: string) => Promise<void>
  interrupt: () => void
  error: Error | null
}

export function useGeminiLive(options: UseGeminiLiveOptions): UseGeminiLiveReturn {
  const {
    studentName,
    grade,
    personality = 'friendly',
    voice = 'Kore',
    onTranscript,
    onAudioReceived,
    onStatusChange,
    onError
  } = options
  
  // State
  const [status, setStatus] = useState<GeminiLiveStatus>('idle')
  const [volume, setVolume] = useState(0)
  const [error, setError] = useState<Error | null>(null)
  
  // Refs
  const abortControllerRef = useRef<AbortController | null>(null)
  const audioContextRef = useRef<AudioContext | null>(null)
  const audioQueueRef = useRef<string[]>([])
  const isPlayingRef = useRef(false)
  const mediaStreamRef = useRef<MediaStream | null>(null)
  const reconnectAttempts = useRef(0)
  const maxReconnectAttempts = 3
  const isSessionActive = useRef(false)
  
  // Status deƒüi≈üikliƒüini bildir
  const updateStatus = useCallback((newStatus: GeminiLiveStatus) => {
    setStatus(newStatus)
    onStatusChange?.(newStatus)
  }, [onStatusChange])
  
  // Audio context olu≈ütur
  const initAudioContext = useCallback(async () => {
    if (!audioContextRef.current) {
      audioContextRef.current = new AudioContext({ sampleRate: 24000 })
    }
    
    if (audioContextRef.current.state === 'suspended') {
      await audioContextRef.current.resume()
    }
    
    return audioContextRef.current
  }, [])
  
  // Audio chunk'ƒ± √ßal
  const playAudioChunk = useCallback(async (base64Audio: string, mimeType: string) => {
    try {
      const ctx = await initAudioContext()
      
      // Base64 -> ArrayBuffer
      const binaryString = atob(base64Audio)
      const bytes = new Uint8Array(binaryString.length)
      for (let i = 0; i < binaryString.length; i++) {
        bytes[i] = binaryString.charCodeAt(i)
      }
      
      // Sample rate'i mime type'dan al
      const sampleRate = mimeType.includes('24000') ? 24000 : 16000
      
      // PCM 16-bit -> Float32
      const pcmData = new Int16Array(bytes.buffer)
      const floatData = new Float32Array(pcmData.length)
      for (let i = 0; i < pcmData.length; i++) {
        floatData[i] = pcmData[i] / 32768
      }
      
      // AudioBuffer olu≈ütur
      const audioBuffer = ctx.createBuffer(1, floatData.length, sampleRate)
      audioBuffer.getChannelData(0).set(floatData)
      
      // √áal
      const source = ctx.createBufferSource()
      source.buffer = audioBuffer
      source.connect(ctx.destination)
      
      source.onended = () => {
        isPlayingRef.current = false
        setVolume(0)
        // Queue'da ba≈üka ses varsa √ßal
        if (audioQueueRef.current.length > 0) {
          const next = audioQueueRef.current.shift()
          if (next) playAudioChunk(next, mimeType)
        } else {
          updateStatus('listening')
        }
      }
      
      isPlayingRef.current = true
      source.start()
      
      // Volume sim√ºlasyonu
      const volumeInterval = setInterval(() => {
        if (isPlayingRef.current) {
          setVolume(0.3 + Math.random() * 0.5)
        } else {
          clearInterval(volumeInterval)
        }
      }, 100)
      
    } catch (err) {
      console.error('Audio playback error:', err)
    }
  }, [initAudioContext, updateStatus])
  
  // Server-side streaming ile Gemini'ye baƒülan
  const streamRequest = useCallback(async (message: string, isAudio: boolean = false) => {
    abortControllerRef.current?.abort()
    abortControllerRef.current = new AbortController()
    
    console.log('üîµ [HOOK] Stream request ba≈ülƒ±yor:', { message: message.substring(0, 50), isAudio })
    updateStatus('processing')
    
    try {
      const response = await fetch('/api/tekno-teacher/live/stream', {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({
          action: isAudio ? 'audio' : 'text',
          studentName,
          grade,
          personality,
          voice,
          [isAudio ? 'audioData' : 'textMessage']: message
        }),
        signal: abortControllerRef.current.signal
      })
      
      console.log('üì° [HOOK] API yanƒ±tƒ±:', response.status, response.statusText)
      
      if (!response.ok) {
        const errorData = await response.json().catch(() => ({ error: 'Bilinmeyen hata' }))
        console.error('‚ùå [HOOK] API hatasƒ±:', errorData)
        throw new Error(errorData.error || `HTTP ${response.status}`)
      }
      
      // SSE stream'i oku
      const reader = response.body?.getReader()
      if (!reader) throw new Error('Stream okunamadƒ±')
      
      const decoder = new TextDecoder()
      let buffer = ''
      let fullText = ''
      let lastHeartbeat = Date.now()
      
      updateStatus('speaking')
      
      while (true) {
        const { done, value } = await reader.read()
        
        if (done) {
          console.log('‚úÖ [HOOK] Stream tamamlandƒ±, toplam metin:', fullText.length, 'karakter')
          break
        }
        
        buffer += decoder.decode(value, { stream: true })
        
        // SSE satƒ±rlarƒ±nƒ± parse et
        const lines = buffer.split('\n')
        buffer = lines.pop() || ''
        
        for (const line of lines) {
          if (line.startsWith('data: ')) {
            try {
              const data = JSON.parse(line.slice(6))
              
              // Heartbeat - baƒülantƒ± canlƒ±
              if (data.type === 'heartbeat') {
                lastHeartbeat = Date.now()
                console.log('üíì [HOOK] Heartbeat alƒ±ndƒ±')
                continue
              }
              
              // Baƒülantƒ± onayƒ±
              if (data.type === 'connected') {
                console.log('üü¢ [HOOK] Baƒülantƒ± onaylandƒ±:', data.studentName)
                reconnectAttempts.current = 0 // Reset reconnect counter
                continue
              }
              
              // Metin chunk'ƒ±
              if (data.type === 'text') {
                fullText += data.content
                console.log('üìù [HOOK] Text chunk:', data.chunk, '-', data.content.substring(0, 30))
                onTranscript?.(data.content, false)
              }
              
              // Audio chunk'ƒ±
              if (data.type === 'audio') {
                console.log('üîä [HOOK] Audio chunk alƒ±ndƒ±')
                onAudioReceived?.(data.data, data.mimeType)
                
                // Audio'yu queue'a ekle veya √ßal
                if (isPlayingRef.current) {
                  audioQueueRef.current.push(data.data)
                } else {
                  playAudioChunk(data.data, data.mimeType)
                }
              }
              
              // Hata
              if (data.type === 'error') {
                console.error('‚ùå [HOOK] Server error:', data.code, data.message)
                throw new Error(`[${data.code || 'ERR'}] ${data.message}`)
              }
              
              // Tamamlandƒ±
              if (data.type === 'done') {
                console.log('‚úÖ [HOOK] Done sinyali, chunks:', data.totalChunks)
                if (!isPlayingRef.current && isSessionActive.current) {
                  updateStatus('listening')
                }
              }
              
            } catch (e: any) {
              if (e.message?.includes('[')) {
                throw e // Re-throw server errors
              }
              console.warn('‚ö†Ô∏è [HOOK] JSON parse hatasƒ±')
            }
          }
        }
        
        // Heartbeat timeout kontrol√º (30 saniye)
        if (Date.now() - lastHeartbeat > 30000) {
          console.warn('‚ö†Ô∏è [HOOK] Heartbeat timeout!')
          break
        }
      }
      
      return fullText
      
    } catch (err: any) {
      if (err.name === 'AbortError') {
        console.log('üõë [HOOK] Stream iptal edildi')
        return
      }
      
      console.error('‚ùå [HOOK] Stream error:', err.message)
      setError(err)
      onError?.(err)
      
      // Yeniden baƒülanma denemesi
      if (isSessionActive.current && reconnectAttempts.current < maxReconnectAttempts) {
        reconnectAttempts.current++
        console.log(`üîÑ [HOOK] Yeniden baƒülanma denemesi ${reconnectAttempts.current}/${maxReconnectAttempts}`)
        updateStatus('connecting')
        
        // 2 saniye bekle ve tekrar dene
        await new Promise(resolve => setTimeout(resolve, 2000))
        
        if (isSessionActive.current) {
          return streamRequest(message, isAudio)
        }
      } else {
        updateStatus('error')
      }
      
      throw err
    }
  }, [studentName, grade, personality, voice, updateStatus, playAudioChunk, onTranscript, onAudioReceived, onError])
  
  // Mikrofonu ba≈ülat (STT i√ßin)
  const startMicrophone = useCallback(async () => {
    // Zaten aktifse tekrar ba≈ülatma
    if (mediaStreamRef.current) {
      const tracks = mediaStreamRef.current.getTracks()
      const activeTracks = tracks.filter(t => t.readyState === 'live')
      if (activeTracks.length > 0) {
        console.log('üé§ [MIC] Mikrofon zaten aktif')
        return true
      }
    }
    
    try {
      console.log('üé§ [MIC] Mikrofon ba≈ülatƒ±lƒ±yor...')
      
      const stream = await navigator.mediaDevices.getUserMedia({
        audio: {
          sampleRate: 16000,
          channelCount: 1,
          echoCancellation: true,
          noiseSuppression: true,
          autoGainControl: true
        }
      })
      
      // Track ended event'i dinle
      stream.getTracks().forEach(track => {
        track.onended = () => {
          console.warn('‚ö†Ô∏è [MIC] Track sonlandƒ±:', track.label)
          
          // Oturum aktifse yeniden ba≈ülat
          if (isSessionActive.current) {
            console.log('üîÑ [MIC] Otomatik yeniden ba≈ülatma...')
            setTimeout(() => {
              if (isSessionActive.current) {
                startMicrophone()
              }
            }, 1000)
          }
        }
        
        track.onmute = () => {
          console.warn('üîá [MIC] Track susturuldu')
        }
        
        track.onunmute = () => {
          console.log('üîä [MIC] Track tekrar aktif')
        }
      })
      
      mediaStreamRef.current = stream
      console.log('‚úÖ [MIC] Mikrofon ba≈ülatƒ±ldƒ±')
      return true
      
    } catch (err: any) {
      console.error('‚ùå [MIC] Mikrofon hatasƒ±:', err.name, err.message)
      
      // Hata t√ºr√ºne g√∂re mesaj
      let errorMessage = 'Mikrofon eri≈üimi reddedildi'
      if (err.name === 'NotAllowedError') {
        errorMessage = 'Mikrofon izni verilmedi. L√ºtfen tarayƒ±cƒ± ayarlarƒ±ndan izin verin.'
      } else if (err.name === 'NotFoundError') {
        errorMessage = 'Mikrofon bulunamadƒ±. L√ºtfen bir mikrofon baƒülayƒ±n.'
      } else if (err.name === 'NotReadableError') {
        errorMessage = 'Mikrofon kullanƒ±lamƒ±yor. Ba≈üka bir uygulama kullanƒ±yor olabilir.'
      }
      
      const error = new Error(errorMessage)
      setError(error)
      onError?.(error)
      return false
    }
  }, [onError])
  
  // Mikrofonu durdur
  const stopMicrophone = useCallback(() => {
    if (mediaStreamRef.current) {
      mediaStreamRef.current.getTracks().forEach(track => {
        track.onended = null
        track.onmute = null
        track.onunmute = null
        track.stop()
      })
      mediaStreamRef.current = null
      console.log('üîá [MIC] Mikrofon durduruldu')
    }
  }, [])
  
  // Baƒülantƒ±yƒ± ba≈ülat
  const connect = useCallback(async () => {
    console.log('üöÄ [HOOK] Baƒülantƒ± ba≈ülatƒ±lƒ±yor...')
    
    updateStatus('connecting')
    setError(null)
    isSessionActive.current = true
    reconnectAttempts.current = 0
    
    try {
      // √ñnce mikrofonu ba≈ülat
      const micStarted = await startMicrophone()
      if (!micStarted) {
        console.warn('‚ö†Ô∏è [HOOK] Mikrofon ba≈ülatƒ±lamadƒ±, sadece metin ile devam ediliyor')
      }
      
      // Ho≈ügeldin mesajƒ± g√∂nder
      console.log('üì§ [HOOK] Ho≈ügeldin mesajƒ± g√∂nderiliyor...')
      await streamRequest(`Merhaba, ben ${studentName}. Benim ${grade}. sƒ±nƒ±f √∂ƒüretmenim ol!`, false)
      
      console.log('‚úÖ [HOOK] Baƒülantƒ± ba≈üarƒ±lƒ±')
      updateStatus('listening')
      
    } catch (err: any) {
      console.error('‚ùå [HOOK] Baƒülantƒ± hatasƒ±:', err.message)
      isSessionActive.current = false
      setError(err)
      onError?.(err)
      updateStatus('error')
    }
  }, [studentName, grade, streamRequest, startMicrophone, updateStatus, onError])
  
  // Baƒülantƒ±yƒ± kes
  const disconnect = useCallback(() => {
    console.log('üîå [HOOK] Baƒülantƒ± kapatƒ±lƒ±yor...')
    
    isSessionActive.current = false
    reconnectAttempts.current = 0
    
    abortControllerRef.current?.abort()
    abortControllerRef.current = null
    
    stopMicrophone()
    
    if (audioContextRef.current) {
      audioContextRef.current.close().catch(() => {})
      audioContextRef.current = null
    }
    
    audioQueueRef.current = []
    isPlayingRef.current = false
    
    updateStatus('idle')
    setVolume(0)
    setError(null)
    
    console.log('‚úÖ [HOOK] Baƒülantƒ± kapatƒ±ldƒ±')
  }, [stopMicrophone, updateStatus])
  
  // Metin g√∂nder
  const sendText = useCallback(async (text: string) => {
    if (!text.trim()) return
    onTranscript?.(text, true)
    await streamRequest(text, false)
  }, [streamRequest, onTranscript])
  
  // Audio g√∂nder (base64)
  const sendAudio = useCallback(async (audioData: string) => {
    await streamRequest(audioData, true)
  }, [streamRequest])
  
  // Konu≈ümayƒ± kes
  const interrupt = useCallback(() => {
    abortControllerRef.current?.abort()
    isPlayingRef.current = false
    audioQueueRef.current = []
    setVolume(0)
    updateStatus('listening')
  }, [updateStatus])
  
  // Cleanup
  useEffect(() => {
    return () => {
      disconnect()
    }
  }, [disconnect])
  
  return {
    status,
    isConnected: ['connected', 'listening', 'speaking', 'processing'].includes(status),
    isListening: status === 'listening',
    isSpeaking: status === 'speaking',
    volume,
    connect,
    disconnect,
    sendText,
    sendAudio,
    interrupt,
    error
  }
}

export default useGeminiLive
