'use client'

/**
 * useGeminiLive Hook
 * Gemini 2.5 Flash Live API ile gerÃ§ek zamanlÄ± sesli sohbet
 * Server-side proxy Ã¼zerinden baÄŸlanÄ±r (CORS sorunu yok)
 * 
 * Ã–zellikler:
 * - Server-side streaming (SSE)
 * - Native audio output
 * - Mikrofon input
 * - VAD (Voice Activity Detection)
 */

import { useState, useRef, useCallback, useEffect } from 'react'

// Types
export type GeminiLiveStatus = 
  | 'idle'
  | 'connecting'
  | 'connected'
  | 'listening'
  | 'speaking'
  | 'processing'
  | 'error'

interface UseGeminiLiveOptions {
  studentName: string
  grade: number
  personality?: 'friendly' | 'strict' | 'motivating'
  voice?: string
  onTranscript?: (text: string, isUser: boolean) => void
  onAudioReceived?: (audioData: string, mimeType: string) => void
  onStatusChange?: (status: GeminiLiveStatus) => void
  onError?: (error: Error) => void
}

interface UseGeminiLiveReturn {
  status: GeminiLiveStatus
  isConnected: boolean
  isListening: boolean
  isSpeaking: boolean
  volume: number
  connect: () => Promise<void>
  disconnect: () => void
  sendText: (text: string) => Promise<void>
  sendAudio: (audioData: string) => Promise<void>
  interrupt: () => void
  error: Error | null
}

export function useGeminiLive(options: UseGeminiLiveOptions): UseGeminiLiveReturn {
  const {
    studentName,
    grade,
    personality = 'friendly',
    voice = 'Kore',
    onTranscript,
    onAudioReceived,
    onStatusChange,
    onError
  } = options
  
  // State
  const [status, setStatus] = useState<GeminiLiveStatus>('idle')
  const [volume, setVolume] = useState(0)
  const [error, setError] = useState<Error | null>(null)
  
  // Refs
  const abortControllerRef = useRef<AbortController | null>(null)
  const audioContextRef = useRef<AudioContext | null>(null)
  const audioQueueRef = useRef<string[]>([])
  const isPlayingRef = useRef(false)
  const mediaStreamRef = useRef<MediaStream | null>(null)
  const reconnectAttempts = useRef(0)
  const maxReconnectAttempts = 3
  const isSessionActive = useRef(false)
  
  // Status deÄŸiÅŸikliÄŸini bildir
  const updateStatus = useCallback((newStatus: GeminiLiveStatus) => {
    setStatus(newStatus)
    onStatusChange?.(newStatus)
  }, [onStatusChange])
  
  // Audio context oluÅŸtur
  const initAudioContext = useCallback(async () => {
    if (!audioContextRef.current) {
      audioContextRef.current = new AudioContext({ sampleRate: 24000 })
    }
    
    if (audioContextRef.current.state === 'suspended') {
      await audioContextRef.current.resume()
    }
    
    return audioContextRef.current
  }, [])
  
  // Audio chunk'Ä± Ã§al
  const playAudioChunk = useCallback(async (base64Audio: string, mimeType: string) => {
    try {
      const ctx = await initAudioContext()
      
      // Base64 -> ArrayBuffer
      const binaryString = atob(base64Audio)
      const bytes = new Uint8Array(binaryString.length)
      for (let i = 0; i < binaryString.length; i++) {
        bytes[i] = binaryString.charCodeAt(i)
      }
      
      // Sample rate'i mime type'dan al
      const sampleRate = mimeType.includes('24000') ? 24000 : 16000
      
      // PCM 16-bit -> Float32
      const pcmData = new Int16Array(bytes.buffer)
      const floatData = new Float32Array(pcmData.length)
      for (let i = 0; i < pcmData.length; i++) {
        floatData[i] = pcmData[i] / 32768
      }
      
      // AudioBuffer oluÅŸtur
      const audioBuffer = ctx.createBuffer(1, floatData.length, sampleRate)
      audioBuffer.getChannelData(0).set(floatData)
      
      // Ã‡al
      const source = ctx.createBufferSource()
      source.buffer = audioBuffer
      source.connect(ctx.destination)
      
      source.onended = () => {
        isPlayingRef.current = false
        setVolume(0)
        // Queue'da baÅŸka ses varsa Ã§al
        if (audioQueueRef.current.length > 0) {
          const next = audioQueueRef.current.shift()
          if (next) playAudioChunk(next, mimeType)
        } else {
          updateStatus('listening')
        }
      }
      
      isPlayingRef.current = true
      source.start()
      
      // Volume simÃ¼lasyonu
      const volumeInterval = setInterval(() => {
        if (isPlayingRef.current) {
          setVolume(0.3 + Math.random() * 0.5)
        } else {
          clearInterval(volumeInterval)
        }
      }, 100)
      
    } catch (err) {
      console.error('Audio playback error:', err)
    }
  }, [initAudioContext, updateStatus])
  
  // Server-side streaming ile Gemini'ye baÄŸlan
  const streamRequest = useCallback(async (message: string, isAudio: boolean = false) => {
    abortControllerRef.current?.abort()
    abortControllerRef.current = new AbortController()
    
    console.log('ğŸ”µ [HOOK] Stream request baÅŸlÄ±yor:', { message: message.substring(0, 50), isAudio })
    updateStatus('processing')
    
    try {
      const response = await fetch('/api/tekno-teacher/live/stream', {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({
          action: isAudio ? 'audio' : 'text',
          studentName,
          grade,
          personality,
          voice,
          [isAudio ? 'audioData' : 'textMessage']: message
        }),
        signal: abortControllerRef.current.signal
      })
      
      console.log('ğŸ“¡ [HOOK] API yanÄ±tÄ±:', response.status, response.statusText)
      
      if (!response.ok) {
        const errorData = await response.json().catch(() => ({ error: 'Bilinmeyen hata' }))
        console.error('âŒ [HOOK] API hatasÄ±:', errorData)
        throw new Error(errorData.error || `HTTP ${response.status}`)
      }
      
      // SSE stream'i oku
      const reader = response.body?.getReader()
      if (!reader) throw new Error('Stream okunamadÄ±')
      
      const decoder = new TextDecoder()
      let buffer = ''
      let fullText = ''
      let lastHeartbeat = Date.now()
      
      updateStatus('speaking')
      
      while (true) {
        const { done, value } = await reader.read()
        
        if (done) {
          console.log('âœ… [HOOK] Stream tamamlandÄ±, toplam metin:', fullText.length, 'karakter')
          break
        }
        
        buffer += decoder.decode(value, { stream: true })
        
        // SSE satÄ±rlarÄ±nÄ± parse et
        const lines = buffer.split('\n')
        buffer = lines.pop() || ''
        
        for (const line of lines) {
          if (line.startsWith('data: ')) {
            try {
              const data = JSON.parse(line.slice(6))
              
              // Heartbeat - baÄŸlantÄ± canlÄ±
              if (data.type === 'heartbeat') {
                lastHeartbeat = Date.now()
                console.log('ğŸ’“ [HOOK] Heartbeat alÄ±ndÄ±')
                continue
              }
              
              // BaÄŸlantÄ± onayÄ±
              if (data.type === 'connected') {
                console.log('ğŸŸ¢ [HOOK] BaÄŸlantÄ± onaylandÄ±:', data.studentName)
                reconnectAttempts.current = 0 // Reset reconnect counter
                continue
              }
              
              // Metin chunk'Ä±
              if (data.type === 'text') {
                fullText += data.content
                console.log('ğŸ“ [HOOK] Text chunk:', data.chunk, '-', data.content.substring(0, 30))
                onTranscript?.(data.content, false)
              }
              
              // Audio chunk'Ä±
              if (data.type === 'audio') {
                console.log('ğŸ”Š [HOOK] Audio chunk alÄ±ndÄ±')
                onAudioReceived?.(data.data, data.mimeType)
                
                // Audio'yu queue'a ekle veya Ã§al
                if (isPlayingRef.current) {
                  audioQueueRef.current.push(data.data)
                } else {
                  playAudioChunk(data.data, data.mimeType)
                }
              }
              
              // Hata
              if (data.type === 'error') {
                console.error('âŒ [HOOK] Server error:', data.code, data.message)
                throw new Error(`[${data.code || 'ERR'}] ${data.message}`)
              }
              
              // TamamlandÄ±
              if (data.type === 'done') {
                console.log('âœ… [HOOK] Done sinyali, chunks:', data.totalChunks)
                if (!isPlayingRef.current && isSessionActive.current) {
                  updateStatus('listening')
                }
              }
              
            } catch (e: any) {
              if (e.message?.includes('[')) {
                throw e // Re-throw server errors
              }
              console.warn('âš ï¸ [HOOK] JSON parse hatasÄ±')
            }
          }
        }
        
        // Heartbeat timeout kontrolÃ¼ (30 saniye)
        if (Date.now() - lastHeartbeat > 30000) {
          console.warn('âš ï¸ [HOOK] Heartbeat timeout!')
          break
        }
      }
      
      return fullText
      
    } catch (err: any) {
      if (err.name === 'AbortError') {
        console.log('ğŸ›‘ [HOOK] Stream iptal edildi')
        return
      }
      
      console.error('âŒ [HOOK] Stream error:', err.message)
      setError(err)
      onError?.(err)
      
      // Yeniden baÄŸlanma denemesi
      if (isSessionActive.current && reconnectAttempts.current < maxReconnectAttempts) {
        reconnectAttempts.current++
        console.log(`ğŸ”„ [HOOK] Yeniden baÄŸlanma denemesi ${reconnectAttempts.current}/${maxReconnectAttempts}`)
        updateStatus('connecting')
        
        // 2 saniye bekle ve tekrar dene
        await new Promise(resolve => setTimeout(resolve, 2000))
        
        if (isSessionActive.current) {
          return streamRequest(message, isAudio)
        }
      } else {
        updateStatus('error')
      }
      
      throw err
    }
  }, [studentName, grade, personality, voice, updateStatus, playAudioChunk, onTranscript, onAudioReceived, onError])
  
  // Mikrofonu baÅŸlat (STT iÃ§in)
  const startMicrophone = useCallback(async () => {
    // Zaten aktifse tekrar baÅŸlatma
    if (mediaStreamRef.current) {
      const tracks = mediaStreamRef.current.getTracks()
      const activeTracks = tracks.filter(t => t.readyState === 'live')
      if (activeTracks.length > 0) {
        console.log('ğŸ¤ [MIC] Mikrofon zaten aktif')
        return true
      }
    }
    
    try {
      console.log('ğŸ¤ [MIC] Mikrofon baÅŸlatÄ±lÄ±yor...')
      
      const stream = await navigator.mediaDevices.getUserMedia({
        audio: {
          sampleRate: 16000,
          channelCount: 1,
          echoCancellation: true,
          noiseSuppression: true,
          autoGainControl: true
        }
      })
      
      // Track ended event'i dinle
      stream.getTracks().forEach(track => {
        track.onended = () => {
          console.warn('âš ï¸ [MIC] Track sonlandÄ±:', track.label)
          
          // Oturum aktifse yeniden baÅŸlat
          if (isSessionActive.current) {
            console.log('ğŸ”„ [MIC] Otomatik yeniden baÅŸlatma...')
            setTimeout(() => {
              if (isSessionActive.current) {
                startMicrophone()
              }
            }, 1000)
          }
        }
        
        track.onmute = () => {
          console.warn('ğŸ”‡ [MIC] Track susturuldu')
        }
        
        track.onunmute = () => {
          console.log('ğŸ”Š [MIC] Track tekrar aktif')
        }
      })
      
      mediaStreamRef.current = stream
      console.log('âœ… [MIC] Mikrofon baÅŸlatÄ±ldÄ±')
      return true
      
    } catch (err: any) {
      console.error('âŒ [MIC] Mikrofon hatasÄ±:', err.name, err.message)
      
      // Hata tÃ¼rÃ¼ne gÃ¶re mesaj
      let errorMessage = 'Mikrofon eriÅŸimi reddedildi'
      if (err.name === 'NotAllowedError') {
        errorMessage = 'Mikrofon izni verilmedi. LÃ¼tfen tarayÄ±cÄ± ayarlarÄ±ndan izin verin.'
      } else if (err.name === 'NotFoundError') {
        errorMessage = 'Mikrofon bulunamadÄ±. LÃ¼tfen bir mikrofon baÄŸlayÄ±n.'
      } else if (err.name === 'NotReadableError') {
        errorMessage = 'Mikrofon kullanÄ±lamÄ±yor. BaÅŸka bir uygulama kullanÄ±yor olabilir.'
      }
      
      const error = new Error(errorMessage)
      setError(error)
      onError?.(error)
      return false
    }
  }, [onError])
  
  // Mikrofonu durdur
  const stopMicrophone = useCallback(() => {
    if (mediaStreamRef.current) {
      mediaStreamRef.current.getTracks().forEach(track => {
        track.onended = null
        track.onmute = null
        track.onunmute = null
        track.stop()
      })
      mediaStreamRef.current = null
      console.log('ğŸ”‡ [MIC] Mikrofon durduruldu')
    }
  }, [])
  
  // Setup request - sadece baÄŸlantÄ± kur, AI hoÅŸgeldin mesajÄ± gÃ¶nderir
  const setupSession = useCallback(async () => {
    abortControllerRef.current?.abort()
    abortControllerRef.current = new AbortController()
    
    console.log('ğŸ”µ [HOOK] Setup session baÅŸlÄ±yor...')
    updateStatus('connecting')
    
    try {
      const response = await fetch('/api/tekno-teacher/live/stream', {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({
          action: 'setup', // Sadece setup, mesaj yok
          studentName,
          grade,
          personality,
          voice
        }),
        signal: abortControllerRef.current.signal
      })
      
      console.log('ğŸ“¡ [HOOK] Setup yanÄ±tÄ±:', response.status)
      
      if (!response.ok) {
        const errorData = await response.json().catch(() => ({ error: 'Bilinmeyen hata' }))
        throw new Error(errorData.error || `HTTP ${response.status}`)
      }
      
      // SSE stream'i oku
      const reader = response.body?.getReader()
      if (!reader) throw new Error('Stream okunamadÄ±')
      
      const decoder = new TextDecoder()
      let buffer = ''
      let fullText = ''
      
      updateStatus('speaking') // AI hoÅŸgeldin mesajÄ± sÃ¶yleyecek
      
      while (true) {
        const { done, value } = await reader.read()
        if (done) break
        
        buffer += decoder.decode(value, { stream: true })
        const lines = buffer.split('\n')
        buffer = lines.pop() || ''
        
        for (const line of lines) {
          if (line.startsWith('data: ')) {
            try {
              const data = JSON.parse(line.slice(6))
              
              // Ping - ignore
              if (data.type === 'ping') continue
              
              // BaÄŸlantÄ± onayÄ±
              if (data.type === 'connected') {
                console.log('ğŸŸ¢ [HOOK] Setup baÄŸlantÄ±sÄ± onaylandÄ±')
                reconnectAttempts.current = 0
                continue
              }
              
              // Metin
              if (data.type === 'text') {
                fullText += data.content
                console.log('ğŸ“ [HOOK] AI:', data.content.substring(0, 50))
                onTranscript?.(data.content, false)
              }
              
              // Audio
              if (data.type === 'audio') {
                console.log('ğŸ”Š [HOOK] Audio chunk')
                onAudioReceived?.(data.data, data.mimeType)
                if (!isPlayingRef.current) {
                  playAudioChunk(data.data, data.mimeType)
                } else {
                  audioQueueRef.current.push(data.data)
                }
              }
              
              // Hata - RAW error gÃ¶ster
              if (data.type === 'error') {
                console.error('âŒ [HOOK] Server error:', data)
                throw new Error(`[${data.code || 'ERR'}] ${data.rawError || data.message}`)
              }
              
              // TamamlandÄ±
              if (data.type === 'done' || data.type === 'stream_end') {
                console.log('âœ… [HOOK] Setup tamamlandÄ±')
              }
              
            } catch (e: any) {
              if (e.message?.startsWith('[')) throw e
            }
          }
        }
      }
      
      return fullText
      
    } catch (err: any) {
      if (err.name === 'AbortError') return
      console.error('âŒ [HOOK] Setup hatasÄ±:', err.message)
      throw err
    }
  }, [studentName, grade, personality, voice, updateStatus, playAudioChunk, onTranscript, onAudioReceived])
  
  // BaÄŸlantÄ±yÄ± baÅŸlat
  const connect = useCallback(async () => {
    console.log('ğŸš€ [HOOK] BaÄŸlantÄ± baÅŸlatÄ±lÄ±yor...')
    
    updateStatus('connecting')
    setError(null)
    isSessionActive.current = true
    reconnectAttempts.current = 0
    
    try {
      // Ã–nce mikrofonu baÅŸlat
      const micStarted = await startMicrophone()
      if (!micStarted) {
        console.warn('âš ï¸ [HOOK] Mikrofon baÅŸlatÄ±lamadÄ±, sadece metin ile devam ediliyor')
      }
      
      // Setup - AI hoÅŸgeldin mesajÄ± gÃ¶nderecek
      console.log('ğŸ“¤ [HOOK] Setup gÃ¶nderiliyor...')
      await setupSession()
      
      console.log('âœ… [HOOK] BaÄŸlantÄ± baÅŸarÄ±lÄ±')
      updateStatus('listening')
      
    } catch (err: any) {
      console.error('âŒ [HOOK] BaÄŸlantÄ± hatasÄ±:', err.message)
      
      // Auto-reconnect (3 deneme)
      if (isSessionActive.current && reconnectAttempts.current < maxReconnectAttempts) {
        reconnectAttempts.current++
        console.log(`ğŸ”„ [HOOK] Yeniden baÄŸlanma ${reconnectAttempts.current}/${maxReconnectAttempts}...`)
        
        await new Promise(r => setTimeout(r, 2000))
        
        if (isSessionActive.current) {
          return connect() // Recursive retry
        }
      }
      
      isSessionActive.current = false
      setError(err)
      onError?.(err)
      updateStatus('error')
    }
  }, [setupSession, startMicrophone, updateStatus, onError])
  
  // BaÄŸlantÄ±yÄ± kes
  const disconnect = useCallback(() => {
    console.log('ğŸ”Œ [HOOK] BaÄŸlantÄ± kapatÄ±lÄ±yor...')
    
    isSessionActive.current = false
    reconnectAttempts.current = 0
    
    abortControllerRef.current?.abort()
    abortControllerRef.current = null
    
    stopMicrophone()
    
    if (audioContextRef.current) {
      audioContextRef.current.close().catch(() => {})
      audioContextRef.current = null
    }
    
    audioQueueRef.current = []
    isPlayingRef.current = false
    
    updateStatus('idle')
    setVolume(0)
    setError(null)
    
    console.log('âœ… [HOOK] BaÄŸlantÄ± kapatÄ±ldÄ±')
  }, [stopMicrophone, updateStatus])
  
  // Metin gÃ¶nder
  const sendText = useCallback(async (text: string) => {
    if (!text.trim()) return
    onTranscript?.(text, true)
    await streamRequest(text, false)
  }, [streamRequest, onTranscript])
  
  // Audio gÃ¶nder (base64)
  const sendAudio = useCallback(async (audioData: string) => {
    await streamRequest(audioData, true)
  }, [streamRequest])
  
  // KonuÅŸmayÄ± kes
  const interrupt = useCallback(() => {
    abortControllerRef.current?.abort()
    isPlayingRef.current = false
    audioQueueRef.current = []
    setVolume(0)
    updateStatus('listening')
  }, [updateStatus])
  
  // Cleanup
  useEffect(() => {
    return () => {
      disconnect()
    }
  }, [disconnect])
  
  return {
    status,
    isConnected: ['connected', 'listening', 'speaking', 'processing'].includes(status),
    isListening: status === 'listening',
    isSpeaking: status === 'speaking',
    volume,
    connect,
    disconnect,
    sendText,
    sendAudio,
    interrupt,
    error
  }
}

export default useGeminiLive
